/**
 * â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 * SORIVA STREAMING SERVICE v1.1 (WORLD-CLASS)
 * â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 * Created by: Amandeep, Punjab, India
 * Created: October 2025
 * Updated: January 22, 2026 (v1.1 - Unified Delta Engine)
 *
 * PURPOSE:
 * Real-time Server-Sent Events (SSE) streaming for AI responses.
 * Provides ChatGPT-like token-by-token streaming experience.
 *
 * FEATURES:
 * âœ… Server-Sent Events (SSE) streaming
 * âœ… Token-by-token response delivery
 * âœ… Progress indicators & metadata
 * âœ… Stream cancellation support
 * âœ… Error recovery & retry logic
 * âœ… Automatic reconnection
 * âœ… Heartbeat mechanism (keep-alive)
 * âœ… Chunk buffering for smooth delivery
 * âœ… Plan-based streaming limits
 * âœ… Connection pooling
 *
 * ARCHITECTURE:
 * - Event-driven
 * - Non-blocking
 * - Memory efficient
 * - Type-safe
 * - Production ready
 *
 * RATING: 100/10 â­â­â­â­â­â­â­â­â­â­
 * â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
 */

import { Response } from 'express';
import { aiService } from '../../../services/ai/ai.service';
import usageService from '../../billing/usage.service';
import memoryManager from '../memoryManager';
import { prisma } from '../../../config/prisma';
import { plansManager, PlanType } from '../../../constants';
import { AIMessage, MessageRole } from '../../../core/ai/providers';

// âœ… v1.1: Using unified delta engine instead of personalityEngine
import { 
  buildDelta, 
  classifyIntent,
  type PlanType as DeltaPlanType 
} from '../../../core/ai/soriva-delta-engine';
// Kundli Flow Integration
import { kundliFlowManager } from '../../../services/astrology/kundli-flow.manager';

// âœ… v2.0: Full feature imports for streaming
import { memoryIntegration } from '../../../services/memory/memory.integration';
import { locationService } from '../../location/location.service';
import { visualEngineService, type VisualOutput } from '../../../services/ai/visual-engine.service';
import { IntelligenceOrchestrator } from '../../../services/ai/intelligence/orchestrator.service';
import {
  buildLeanSystemPrompt,
  buildLeanSearchContext,
  getPromptTier,
  selectLeanHistory,
  isFollowUpQuery,
} from '../lean-prompt.service';

// ğŸ—œï¸ Context Compressor for long conversations
import { contextCompressor } from '../utils/context-compressor';

// âœ… v2.1: Mistral Web Search Integration (Feb 23, 2026)
import { MistralProvider } from '../../../core/ai/providers/mistral.provider';

const intelligenceOrchestrator = IntelligenceOrchestrator.getInstance();

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// v2.9: AI-BASED AUTO MODE DETECTION (February 25, 2026)
// Uses IntelligenceOrchestrator's AI analysis - NO static keywords!
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

type DetectedMode = 'normal' | 'code';

interface ModeDetectionResult {
  mode: DetectedMode;
  confidence: number;
  reason: string;
}

/**
 * Mode detection simplified - only normal and code modes
 * Code mode is premium feature (Pro/Apex/Sovereign only)
 */
function detectModeFromOrchestrator(orchestratorResult: any): ModeDetectionResult {
  // Always return normal - code mode requires explicit user selection
  return {
    mode: 'normal',
    confidence: 1.0,
    reason: 'Auto-detection disabled. Code mode requires explicit selection.',
  };
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// DYNAMIC CONFIGURATION
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class StreamingConfig {
  /**
   * Enable/disable streaming globally
   */
  static readonly ENABLED = process.env.STREAMING_ENABLED !== 'false';

  /**
   * Chunk size for buffering (tokens per chunk)
   */
  static readonly CHUNK_SIZE = parseInt(process.env.STREAMING_CHUNK_SIZE || '5');

  /**
   * Delay between chunks (milliseconds)
   * Lower = faster streaming, higher = smoother animation
   */
  static readonly CHUNK_DELAY_MS = parseInt(process.env.STREAMING_CHUNK_DELAY_MS || '30');

  /**
   * Heartbeat interval (seconds)
   * Keeps connection alive
   */
  static readonly HEARTBEAT_INTERVAL = parseInt(process.env.STREAMING_HEARTBEAT_INTERVAL || '15');

  /**
   * Maximum stream duration (seconds)
   * Prevents infinite streams
   */
  static readonly MAX_STREAM_DURATION = parseInt(process.env.STREAMING_MAX_DURATION || '300');

  /**
   * Enable progress indicators
   */
  static readonly SHOW_PROGRESS = process.env.STREAMING_SHOW_PROGRESS !== 'false';

  /**
   * Enable metadata events
   */
  static readonly SEND_METADATA = process.env.STREAMING_SEND_METADATA !== 'false';

  /**
   * Auto-retry on stream failure
   */
  static readonly AUTO_RETRY = process.env.STREAMING_AUTO_RETRY === 'true';

  /**
   * Max retry attempts
   */
  static readonly MAX_RETRIES = parseInt(process.env.STREAMING_MAX_RETRIES || '2');

  /**
   * Plan-based streaming priority
   */
  static readonly PLAN_PRIORITIES: Record<PlanType, number> = {
    [PlanType.STARTER]: 1, // Lowest priority
    [PlanType.LITE]: 1, // âœ… LITE - Same as STARTER (lowest priority)
    [PlanType.PLUS]: 2,
    [PlanType.PRO]: 3,
    [PlanType.APEX]: 4,
    [PlanType.SOVEREIGN]: 10
  };
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// TYPES & INTERFACES
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

interface StreamChatOptions {
  userId: string;
  message: string;
  sessionId?: string;
  parentMessageId?: string;
  temperature?: number;
  onChunk?: (chunk: string) => void;
}

// âœ… v2.0: Full-featured streaming options
interface StreamingChatOptionsV2 {
  userId: string;
  message: string;
  sessionId?: string;
  mode?: string;
  conversationHistory?: Array<{ role: string; content: string }>;
  region?: 'IN' | 'INTL';
  language?: 'hindi' | 'english' | 'hinglish';  // â† ADD THIS
  onChunk: (chunk: string) => void;
  onComplete: (result: {
    sessionId?: string;
    visual?: VisualOutput['visual'];
    webSources?: Array<{ title: string; url: string }>;
    compactionMessage?: string;  // ğŸ—œï¸ Context compaction message for long conversations
    // v2.9: Auto-detected mode for frontend UI sync
    detectedMode?: {
      mode: 'normal' | 'code';
      confidence: number;
      reason: string;
    };
  }) => void;
  onError: (error: Error) => void;
}

interface StreamMetadata {
  type: 'metadata';
  data: {
    model?: string;
    tokensUsed?: number;
    wordsUsed?: number;
    streamDuration?: number;
  };
}

interface StreamProgress {
  type: 'progress';
  data: {
    percentage: number;
    estimatedTimeRemaining?: number;
  };
}

interface StreamChunk {
  type: 'chunk';
  data: {
    content: string;
    index: number;
  };
}

interface StreamComplete {
  type: 'complete';
  data: {
    messageId: string;
    totalTokens: number;
    totalWords: number;
    streamDuration: number;
  };
}

interface StreamError {
  type: 'error';
  data: {
    error: string;
    code?: string;
    retryable?: boolean;
  };
}

type StreamEvent = StreamMetadata | StreamProgress | StreamChunk | StreamComplete | StreamError;

interface ActiveStream {
  id: string;
  userId: string;
  startTime: number;
  response: Response;
  aborted: boolean;
  heartbeatInterval?: NodeJS.Timeout;
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// STREAMING SERVICE CLASS
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

export class StreamingService {
  private static instance: StreamingService;

  // Track active streams
  private activeStreams: Map<string, ActiveStream>;

  private constructor() {
    this.activeStreams = new Map();

    console.log('[StreamingService] ğŸŒŠ Initialized with SSE streaming');
    console.log('[StreamingService] Config:', {
      enabled: StreamingConfig.ENABLED,
      chunkSize: StreamingConfig.CHUNK_SIZE,
      chunkDelay: StreamingConfig.CHUNK_DELAY_MS + 'ms',
      heartbeat: StreamingConfig.HEARTBEAT_INTERVAL + 's',
      maxDuration: StreamingConfig.MAX_STREAM_DURATION + 's',
    });
  }

  /**
   * Get singleton instance
   */
  static getInstance(): StreamingService {
    if (!StreamingService.instance) {
      StreamingService.instance = new StreamingService();
    }
    return StreamingService.instance;
  }

  /**
   * Initialize SSE connection
   */
  initializeStream(res: Response, streamId: string): void {
    // Set SSE headers
    res.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
      'X-Accel-Buffering': 'no', // Disable nginx buffering
    });

    console.log('[StreamingService] ğŸŒŠ Stream initialized:', streamId);
  }

  /**
   * Send SSE event
   */
  private sendEvent(res: Response, event: StreamEvent): boolean {
    try {
      const data = JSON.stringify(event);
      res.write(`event: ${event.type}\n`);
      res.write(`data: ${data}\n\n`);
      return true;
    } catch (error) {
      console.error('[StreamingService] Send event error:', error);
      return false;
    }
  }

  /**
   * Send heartbeat (keep-alive)
   */
  private sendHeartbeat(res: Response): void {
    try {
      res.write(': heartbeat\n\n');
    } catch (error) {
      console.error('[StreamingService] Heartbeat error:', error);
    }
  }

  /**
   * Stream chat response
   */
  async streamChat(options: StreamChatOptions, res: Response): Promise<void> {
    const streamId = this.generateStreamId();
    const startTime = Date.now();
    const retryCount = 0;

    const { userId, message, sessionId, parentMessageId, temperature, onChunk } = options;

    try {
      // ========================================
      // STEP 1: CHECK IF STREAMING ENABLED
      // ========================================

      if (!StreamingConfig.ENABLED) {
        this.sendEvent(res, {
          type: 'error',
          data: {
            error: 'Streaming is disabled',
            code: 'STREAMING_DISABLED',
          },
        });
        res.end();
        return;
      }

      // ========================================
      // STEP 2: INITIALIZE STREAM
      // ========================================

      this.initializeStream(res, streamId);

      // Track active stream
      const activeStream: ActiveStream = {
        id: streamId,
        userId,
        startTime,
        response: res,
        aborted: false,
      };

      this.activeStreams.set(streamId, activeStream);

      // Setup heartbeat
      activeStream.heartbeatInterval = setInterval(() => {
        if (!activeStream.aborted) {
          this.sendHeartbeat(res);
        }
      }, StreamingConfig.HEARTBEAT_INTERVAL * 1000);

      // ========================================
      // STEP 3: GET USER & VALIDATE
      // ========================================

      const user = await prisma.user.findUnique({
        where: { id: userId },
      });

      if (!user) {
        throw new Error('User not found');
      }

      // ========================================
      // STEP 4: CHECK USAGE LIMITS
      // ========================================

      const usage = await usageService.getUserStatus(userId);
      const plan = plansManager.getPlan(user.planType as PlanType);
      // ğŸ” DEBUG: Check what's happening
console.log('[StreamingService] DEBUG:', {
  planType: user.planType,
  planName: usage.plan,
  canChat: usage.canChat,
  statusMessage: usage.statusMessage,
});

      if (!plan) {
        throw new Error('Invalid plan type');
      }

      // Check if user can chat (token-based limits)
      if (!usage.canChat) {
        this.sendEvent(res, {
          type: 'error',
          data: {
            error: usage.statusMessage || 'Usage limit reached. Please upgrade your plan.',
            code: 'LIMIT_EXCEEDED',
          },
        });
        this.cleanupStream(streamId);
        return;
      }

      // ========================================
      // STEP 5: CREATE/GET CHAT SESSION
      // ========================================

      let chatSession;

      if (sessionId) {
        chatSession = await prisma.chatSession.findUnique({
          where: { id: sessionId },
        });

        if (!chatSession || chatSession.userId !== userId) {
          throw new Error('Invalid session');
        }
      } else {
        chatSession = await prisma.chatSession.create({
          data: {
            userId,
            title: message.substring(0, 50) + (message.length > 50 ? '...' : ''),
          },
        });
      }

      // ========================================
      // STEP 6: SAVE USER MESSAGE
      // ========================================

      const userMessageWords = message.split(/\s+/).length;

      const userMessage = await prisma.message.create({
        data: {
          sessionId: chatSession.id,
          userId,
          role: 'user',
          content: message,
          wordsUsed: userMessageWords,
        },
      });

      // ========================================
      // STEP 7: GET CONVERSATION HISTORY
      // ========================================

      const historyLimit = (user.memoryDays || 5) * 10;

      const history = await prisma.message.findMany({
        where: { sessionId: chatSession.id },
        orderBy: { createdAt: 'asc' },
        take: historyLimit,
      });

      const conversationHistory: AIMessage[] = history
        .filter((m) => m.id !== userMessage.id)
        .map((m) => ({
          role: m.role === 'user' ? MessageRole.USER : MessageRole.ASSISTANT,
          content: m.content,
        }));

      // ========================================
      // STEP 8: GET MEMORY & SYSTEM PROMPT (v1.1 - Using Delta Engine)
      // ========================================

      const memoryContext = await memoryManager.getMemoryContext(userId);

      // âœ… v1.1: Use unified delta engine instead of personalityEngine
      const planString = user.planType as DeltaPlanType;
      const intent = classifyIntent(planString, message);
      const systemPrompt = buildDelta(planString, intent);

      // ========================================
      // STEP 9: STREAM AI RESPONSE
      // ========================================

      // Send metadata
      if (StreamingConfig.SEND_METADATA) {
        this.sendEvent(res, {
          type: 'metadata',
          data: {
            model: plan.aiModels[0].modelId,
          },
        });
      }

      // Simulate streaming (replace with actual AI streaming)
      let streamedContent = '';
      let chunkIndex = 0;

      // In production, use actual AI streaming API
      const aiResponse = await aiService.chat({
        message,
        conversationHistory,
        memory: memoryContext,
        userId,
        planType: user.planType as any,
        language: 'english',
        userName: user.name || undefined,
        temperature: temperature || 0.7,
        systemPrompt, // âœ… v1.1: Using delta engine system prompt
      });

      // Stream the response in chunks
      const words = aiResponse.message.split(' ');
      const totalWords = words.length;

      for (let i = 0; i < words.length; i += StreamingConfig.CHUNK_SIZE) {
        if (activeStream.aborted) {
          break;
        }

        const chunk = words.slice(i, i + StreamingConfig.CHUNK_SIZE).join(' ') + ' ';

        streamedContent += chunk;

        // Send chunk
        this.sendEvent(res, {
          type: 'chunk',
          data: {
            content: chunk,
            index: chunkIndex++,
          },
        });

        // Call onChunk callback if provided
        if (onChunk) {
          onChunk(chunk);
        }

        // Send progress
        if (StreamingConfig.SHOW_PROGRESS) {
          const progress = Math.round((i / totalWords) * 100);
          this.sendEvent(res, {
            type: 'progress',
            data: {
              percentage: progress,
            },
          });
        }

        // Delay for smooth streaming
        await this.delay(StreamingConfig.CHUNK_DELAY_MS);
      }

      // ========================================
      // STEP 10: SAVE AI MESSAGE
      // ========================================

      const assistantMessage = await prisma.message.create({
        data: {
          sessionId: chatSession.id,
          userId,
          role: 'assistant',
          content: streamedContent.trim(),
          aiModel: aiResponse.metadata.model,
          tokens: aiResponse.usage.totalTokens,
          wordsUsed: aiResponse.usage.wordsUsed - userMessageWords,
        },
      });

      // ========================================
      // STEP 11: UPDATE SESSION
      // ========================================

      await prisma.chatSession.update({
        where: { id: chatSession.id },
        data: {
          messageCount: { increment: 2 },
          totalTokens: { increment: aiResponse.usage.totalTokens },
          lastMessageAt: new Date(),
        },
      });

      // ========================================
      // STEP 12: SEND COMPLETE EVENT
      // ========================================

      const streamDuration = Date.now() - startTime;

      this.sendEvent(res, {
        type: 'complete',
        data: {
          messageId: assistantMessage.id,
          totalTokens: aiResponse.usage.totalTokens,
          totalWords: aiResponse.usage.wordsUsed,
          streamDuration,
        },
      });

      console.log('[StreamingService] âœ… Stream complete:', {
        streamId,
        duration: streamDuration + 'ms',
        chunks: chunkIndex,
        words: totalWords,
      });

      // ========================================
      // STEP 13: CLEANUP
      // ========================================

      memoryManager.clearCache(userId);
      this.cleanupStream(streamId);
    } catch (error: any) {
      console.error('[StreamingService] Stream error:', error);

      // Send error event
      this.sendEvent(res, {
        type: 'error',
        data: {
          error: error.message || 'Streaming failed',
          code: error.code || 'STREAM_ERROR',
          retryable: StreamingConfig.AUTO_RETRY && retryCount < StreamingConfig.MAX_RETRIES,
        },
      });

      this.cleanupStream(streamId);
    }
  }

  // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  // v2.0: FULL-FEATURED STREAMING (Memory, Search, Visual, etc.)
  // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  /**
   * ğŸš€ Stream chat with ALL features
   */
  async streamChatWithAllFeatures(options: StreamingChatOptionsV2): Promise<void> {
    const { userId, message, mode, conversationHistory, region, onChunk, onComplete, onError, language } = options;
    
    const startTime = Date.now();
    let fullResponse = '';
    let visualData: VisualOutput = { hasVisual: false };
    let webSources: Array<{ title: string; url: string }> = [];

    try {
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 1. FETCH USER & PLAN
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      const user = await prisma.user.findUnique({
        where: { id: userId },
        select: {
          id: true,
          name: true,
          planType: true,
          timezone: true,
          memoryDays: true,
        },
      });

      if (!user) {
        throw new Error('User not found');
      }

      console.log('[StreamingChat v2.0] ğŸš€ Starting:', {
        userId: userId.slice(0, 8),
        plan: user.planType,
        requestedMode: mode || 'normal',
        messageLength: message.length,
      });

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 2. MEMORY INTEGRATION
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      let memoryPromptContext = '';
      
      if (user.planType !== 'STARTER') {
        try {
          const memoryData = await memoryIntegration.getContextForChat(userId, '');
          if (memoryData) {
            memoryPromptContext = memoryData.promptContext;
            console.log('[StreamingChat v2.0] ğŸ§  Memory loaded:', {
              tokens: memoryData.estimatedTokens,
            });
          }
        } catch (err) {
          console.error('[StreamingChat v2.0] Memory fetch failed:', err);
        }
      }

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 3. LOCATION CONTEXT
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      const locationContext = await locationService.getSearchContext(userId);
      const locationString = locationContext?.searchString || 'India';
      
      console.log('[StreamingChat v2.0] ğŸ“ Location:', locationString);

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 4. INTELLIGENCE ORCHESTRATOR - Query Analysis
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      let orchestratorResult: any = null;
      let detectedLanguage = 'hinglish';
      let isSearchQuery = false;
      
      try {
        orchestratorResult = await intelligenceOrchestrator.processWithPreprocessor({
          userId,
          message,
          planType: user.planType as PlanType,
          userName: user.name || undefined,
          userLocation: locationString,
          conversationHistory: (conversationHistory || []).map(m => ({
            role: m.role as 'user' | 'assistant',
            content: m.content,
          })),
        });

        console.log('[StreamingChat v2.0] ğŸ”± Orchestrator:', {
          complexity: orchestratorResult.complexity,
          searchNeeded: orchestratorResult.searchNeeded,
          domain: orchestratorResult.domain,
        });

        isSearchQuery = orchestratorResult.searchNeeded === true;
        detectedLanguage = orchestratorResult.enhancedResult?.analysis?.tone?.language || 'hinglish';
        
      } catch (e: any) {
        console.warn('[StreamingChat v2.0] âš ï¸ Orchestrator failed:', e.message);
      }

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // v2.9: AUTO MODE DETECTION (Uses Orchestrator's AI analysis)
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      let effectiveMode: DetectedMode = (mode as DetectedMode) || 'normal';
      let modeDetectionResult: ModeDetectionResult | null = null;
      
      // Only auto-detect if frontend sent 'normal', 'auto', or nothing
      if (!mode || mode === 'normal' || mode === 'auto') {
        modeDetectionResult = detectModeFromOrchestrator(orchestratorResult);
        effectiveMode = modeDetectionResult.mode;
        
        console.log('[StreamingChat v2.9] ğŸ¯ Auto Mode Detection:', {
          detected: modeDetectionResult.mode,
          confidence: modeDetectionResult.confidence.toFixed(2),
          reason: modeDetectionResult.reason,
        });
      } else {
        // User explicitly selected a mode - respect their choice
        console.log('[StreamingChat v2.9] ğŸ‘¤ User selected mode:', mode);
      }

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // v3.0: 100% DYNAMIC SEARCH DECISION (Trust Orchestrator)
      // Zero static regex - Orchestrator AI already analyzed the query
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // Orchestrator has already decided if search is needed
      // We trust its AI-based analysis completely
      // No override needed - orchestrator handles all cases:
      // - Questions, current data, availability, pricing, news, reviews
      // - Excludes: greetings, coding, creative, general knowledge
      console.log('[StreamingChat v3.0] ğŸ¯ Search decision from Orchestrator:', {
        searchNeeded: isSearchQuery,
        domain: orchestratorResult?.domain,
        intent: orchestratorResult?.enhancedResult?.analysis?.intent
      });

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // v3.0: 100% DYNAMIC FOLLOW-UP DETECTION (Trust Orchestrator)
      // Zero static regex - Orchestrator AI handles context analysis
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      let isFollowUpSearch = false;
      
      // Orchestrator already analyzes conversation context
      // It detects follow-ups through AI understanding, not keyword matching
      const orchestratorDetectedFollowUp = orchestratorResult?.enhancedResult?.analysis?.isFollowUp === true;
      const orchestratorContext = orchestratorResult?.enhancedResult?.analysis?.context;
      
      // If orchestrator says it's a follow-up AND search is needed, trust it
      if (orchestratorDetectedFollowUp && isSearchQuery) {
        isFollowUpSearch = true;
        console.log('[StreamingChat v3.0] ğŸ”„ Follow-up detected (AI-based):', {
          context: orchestratorContext,
          searchNeeded: isSearchQuery
        });
      }

     // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // v3.0: 100% DYNAMIC WEB SEARCH (Mistral Intelligence)
      // Zero static regex - Let Mistral AI handle everything
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      let searchContext = '';
      
      if (isSearchQuery) {
        try {
          console.log('[StreamingChat v3.0] ğŸ” Web search triggered...');
          
          const mistralApiKey = process.env.MISTRAL_API_KEY;
          if (mistralApiKey) {
            const mistralProvider = new MistralProvider({
              apiKey: mistralApiKey,
              model: 'mistral-large-latest' as any,
              provider: 'MISTRAL' as any,
            });
            
            // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            // v3.0: INTELLIGENT QUERY BUILDING
            // Trust Orchestrator's analysis - it already extracted the core
            // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            
            // Get optimized search query from orchestrator (AI-extracted core)
            const coreQuery = orchestratorResult?.enhancedResult?.analysis?.core || message;
            
            // Get context from orchestrator for smarter search
            const searchCategory = orchestratorResult?.enhancedResult?.analysis?.category || '';
            const needsRecency = orchestratorResult?.enhancedResult?.analysis?.needsRecency === true;
            const isFollowUp = orchestratorResult?.enhancedResult?.analysis?.isFollowUp === true;
            const previousContext = orchestratorResult?.enhancedResult?.analysis?.previousContext || '';
            
            // Build smart search query
            let searchQuery = coreQuery;
            
            // If follow-up, orchestrator provides the context
            if (isFollowUp && previousContext) {
              searchQuery = `${previousContext} ${coreQuery}`;
              console.log('[StreamingChat v3.0] ğŸ”— Follow-up query:', searchQuery);
            }
            
            // Add location context (simple, dynamic)
            const userCountry = locationString.includes('India') ? 'India' : 
              locationString.split(',').pop()?.trim() || 'India';
            
            // Add recency filter only if orchestrator says needed
            if (needsRecency) {
              const now = new Date();
              const threeMonthsAgo = new Date(now);
              threeMonthsAgo.setMonth(threeMonthsAgo.getMonth() - 3);
              const monthNames = ['January', 'February', 'March', 'April', 'May', 'June', 
                'July', 'August', 'September', 'October', 'November', 'December'];
              const cutoffMonth = monthNames[threeMonthsAgo.getMonth()];
              const cutoffYear = threeMonthsAgo.getFullYear();
              
              searchQuery = `${searchQuery} ${userCountry} after ${cutoffMonth} ${cutoffYear}`;
              console.log('[StreamingChat v3.0] ğŸ“… Recency filter applied');
            }
            
            console.log('[StreamingChat v3.0] ğŸ¯ Final search query:', searchQuery);
            
            // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            // Execute search - Mistral handles the intelligence
            // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            const searchResult = await mistralProvider.searchWeb(searchQuery);
            
            if (searchResult && searchResult.answer) {
              console.log('[StreamingChat v3.0] âœ… Web search complete:', {
                answerLength: searchResult.answer.length,
                sources: searchResult.sources?.length || 0,
                timeMs: searchResult.timeMs,
              });

              // Clean, minimal context injection
              searchContext = `\n\n[LIVE WEB DATA - ${new Date().toLocaleDateString('en-IN', { month: 'long', year: 'numeric' })}]
              ${searchResult.answer}
                [END WEB DATA]
              Use this web data to answer. If web data contradicts your knowledge, trust web data.`;

              // Store sources
              if (searchResult.sources && searchResult.sources.length > 0) {
                webSources = searchResult.sources.map(s => ({
                  title: s.title,
                  url: s.url,
                }));
              }
            }
          } else {
            console.warn('[StreamingChat v3.0] âš ï¸ MISTRAL_API_KEY not set');
          }
        } catch (searchError: any) {
          console.error('[StreamingChat v3.0] âŒ Web search failed:', searchError.message);
        }
      }

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 4.5 KUNDLI FLOW CHECK
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      let kundliData: any = null;

      try {
      const kundliResult = await kundliFlowManager.process({
        userId: user.id,
        message: message,
        language: (language || detectedLanguage) as 'hindi' | 'english' | 'hinglish',
      });

        if (kundliResult.isKundliFlow) {
          console.log('[StreamingChat v2.0] ğŸ”® Kundli flow active');
          
          // Direct response - skip LLM, send response directly
          if (kundliResult.skipLLM && kundliResult.directResponse) {
            onChunk(kundliResult.directResponse);
            onComplete({
              visual: undefined,
              webSources: undefined,
            });
            console.log('[StreamingChat v2.0] âœ… Kundli direct response sent');
            return; // Exit early - no need for LLM
          }
          
          kundliData = kundliResult.kundliData;
        }
      } catch (e: any) {
        console.warn('[StreamingChat v2.0] âš ï¸ Kundli flow error:', e.message);
      }

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 5. LEAN PROMPT BUILD
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      const isGreeting = /^(hi|hello|hey|namaste|hii+)\b/i.test(message.trim());
      const isTimeQuery = /\b(time|samay|waqt|baje|clock|current time|abhi)\b/i.test(message);
      
      // Force FULL tier for time queries so dateTime is included
      let promptTier = getPromptTier(
        isGreeting,
        isSearchQuery,
        (orchestratorResult?.complexity || 'SIMPLE') as 'SIMPLE' | 'MEDIUM' | 'HIGH'
      );
      
      if (isTimeQuery) {
        promptTier = 'FULL';
        console.log('[StreamingChat v2.0] â° Time query detected - using FULL tier');
      }

      // Get current date/time
      const now = new Date();
      const currentDateTime = now.toLocaleString('en-IN', {
        timeZone: user.timezone || 'Asia/Kolkata',
        weekday: 'long',
        year: 'numeric',
        month: 'long',
        day: 'numeric',
        hour: '2-digit',
        minute: '2-digit',
        hour12: true,
      });

      let finalSystemPrompt = buildLeanSystemPrompt({
        tier: promptTier,
        userName: user.name || undefined,
        language: detectedLanguage as 'english' | 'hinglish' | 'hindi',
        location: promptTier === 'FULL' ? locationString : undefined,
        dateTime: promptTier === 'FULL' ? currentDateTime : undefined,
        planType: user.planType,
        mode: effectiveMode as 'normal' | 'code',
      });

      // Add memory context
      if (memoryPromptContext) {
        finalSystemPrompt += '\n\n' + memoryPromptContext;
      }

      // âœ… v2.1: Add web search context
      if (searchContext) {
        finalSystemPrompt += searchContext;
      }

      console.log('[StreamingChat v2.0] ğŸ¯ Prompt:', {
        tier: promptTier,
        length: finalSystemPrompt.length,
        hasMemory: memoryPromptContext.length > 0,
        hasSearch: searchContext.length > 0,
      });

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 6. VISUAL ENGINE CHECK (Learn Mode)
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // v3.0: DYNAMIC VISUAL ENGINE (Based on Orchestrator Analysis)
      // No mode dependency - visuals for educational/explainer queries
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      let visualAnalysis = { needsVisual: false, visualPrompt: null as string | null };
      
      // Check if orchestrator detected educational/visual-worthy content
      const orchestratorDomain = orchestratorResult?.domain || 'general';
      const orchestratorCategory = orchestratorResult?.enhancedResult?.analysis?.category || '';
      const orchestratorIntent = orchestratorResult?.enhancedResult?.analysis?.intent || '';
      
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // v3.0: 100% DYNAMIC VISUAL DECISION
      // Trust Orchestrator's AI analysis - it knows if visual helps
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      // Orchestrator already analyzed - check if it suggests visual
      const orchestratorSuggestsVisual = orchestratorResult?.enhancedResult?.analysis?.needsVisual === true;
      const orchestratorComplexity = orchestratorResult?.complexity || 'SIMPLE';
      const orchestratorIntentType = orchestratorResult?.enhancedResult?.analysis?.intent || orchestratorResult?.intent || '';
      
      // Enable visual if:
      // 1. Orchestrator explicitly says needsVisual
      // 2. OR complexity is MEDIUM/HIGH (complex topics benefit from visuals)
      // 3. OR intent is LEARNING/EDUCATIONAL
      const shouldEnableVisual = (
        orchestratorSuggestsVisual ||
        orchestratorComplexity === 'MEDIUM' ||
        orchestratorComplexity === 'HIGH' ||
        /LEARNING|EDUCATIONAL|TECHNICAL|ANALYTICAL/i.test(orchestratorIntentType)
      );
      
      if (shouldEnableVisual) {
        visualAnalysis.needsVisual = true;
        console.log('[StreamingChat v3.0] ğŸ“Š Visual enabled:', {
          reason: orchestratorSuggestsVisual ? 'orchestrator' : 
                  /LEARNING|EDUCATIONAL/i.test(orchestratorIntentType) ? 'learning-intent' : 'complexity',
          complexity: orchestratorComplexity,
          intent: orchestratorIntentType
        });
      }

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 7. PREPARE HISTORY
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      let historyForAI = selectLeanHistory(
        (conversationHistory || []).map(m => ({
          role: m.role as 'user' | 'assistant',
          content: m.content,
        })),
        isSearchQuery,
        isFollowUpQuery(message)
      );

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 7.5 CONTEXT COMPRESSION (for long conversations)
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      let compactionMessage: string | undefined;
      
      if (historyForAI.length >= 15) {
        const compressResult = contextCompressor.compress(
          historyForAI.map(m => ({
            role: m.role as 'user' | 'assistant' | 'system',
            content: m.content,
          })),
          user.planType as PlanType,
          { keepRecent: 5 }
        );
        
        if (compressResult.messagesRemoved > 0) {
          historyForAI = compressResult.compressed.map((msg, idx) => ({
            role: msg.role as 'user' | 'assistant',
            content: msg.content,
          }));
          compactionMessage = compressResult.compactionMessage;
          
          console.log('[StreamingChat v2.0] ğŸ—œï¸ Context compressed:', {
            before: conversationHistory?.length || 0,
            after: historyForAI.length,
            removed: compressResult.messagesRemoved,
          });
        }
      }

      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      // 8. REAL STREAMING AI CALL
      // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
      
      console.log('[StreamingChat v2.0] ğŸ¤– Starting REAL AI stream...');

      await aiService.streamChat({
        userId,
        message,
        planType: user.planType as any,
        systemPrompt: finalSystemPrompt,
        conversationHistory: historyForAI as AIMessage[],
        region: region || 'IN',
        mode: effectiveMode,  // v2.9: Pass mode for model routing
        
        onChunk: (chunk: string) => {
          fullResponse += chunk;
          
          // Learn Mode: Filter visual JSON from stream
          if (visualAnalysis.needsVisual) {
            // Don't stream if we're inside a code block (potential JSON)
            const openBlocks = (fullResponse.match(/```/g) || []).length;
            const isInsideCodeBlock = openBlocks % 2 === 1;
            
            if (isInsideCodeBlock) {
              // Inside code block - don't send this chunk
              return;
            }
            
            // Check if chunk contains start of code block
            if (chunk.includes('```')) {
              // Send only the part before the code block
              const beforeBlock = chunk.split('```')[0];
              if (beforeBlock.trim()) {
                onChunk(beforeBlock);
              }
              return;
            }
          }
          
          onChunk(chunk);
        },
        
        onComplete: async () => {
          console.log('[StreamingChat v2.0] âœ… Stream complete:', {
            responseLength: fullResponse.length,
            timeMs: Date.now() - startTime,
          });

          // Parse visual if needed
          if (visualAnalysis.needsVisual) {
            visualData = visualEngineService.parseVisualFromResponse(fullResponse);
            if (visualData.hasVisual) {
              console.log('[StreamingChat v2.0] ğŸ“Š Visual generated:', visualData.visual?.type);
            }
          }

          onComplete({
            sessionId: options.sessionId,
            visual: visualData.hasVisual ? visualData.visual : undefined,
            webSources: webSources.length > 0 ? webSources : undefined,
            compactionMessage,
            // v2.9: Return detected mode for frontend UI sync
            detectedMode: modeDetectionResult ? {
              mode: modeDetectionResult.mode,
              confidence: modeDetectionResult.confidence,
              reason: modeDetectionResult.reason,
            } : undefined,
          });
        },
        
        onError: (error: Error) => {
          console.error('[StreamingChat v2.0] âŒ Stream error:', error.message);
          onError(error);
        },
      });

    } catch (error: any) {
      console.error('[StreamingChat v2.0] âŒ Fatal error:', error.message);
      onError(error);
    }
  }

  /**
   * Cancel an active stream
   */
  cancelStream(streamId: string): boolean {
    const stream = this.activeStreams.get(streamId);

    if (!stream) {
      return false;
    }

    stream.aborted = true;

    this.sendEvent(stream.response, {
      type: 'error',
      data: {
        error: 'Stream cancelled by user',
        code: 'STREAM_CANCELLED',
      },
    });

    this.cleanupStream(streamId);

    console.log('[StreamingService] ğŸ›‘ Stream cancelled:', streamId);

    return true;
  }

  /**
   * Get active streams count
   */
  getActiveStreamsCount(): number {
    return this.activeStreams.size;
  }

  /**
   * Get active streams for a user
   */
  getUserActiveStreams(userId: string): string[] {
    const streams: string[] = [];

    for (const [streamId, stream] of this.activeStreams.entries()) {
      if (stream.userId === userId) {
        streams.push(streamId);
      }
    }

    return streams;
  }

  // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  // PRIVATE HELPER METHODS
  // â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  /**
   * Generate unique stream ID
   */
  private generateStreamId(): string {
    return `stream_${Date.now()}_${Math.random().toString(36).substring(7)}`;
  }

  /**
   * Cleanup stream resources
   */
  private cleanupStream(streamId: string): void {
    const stream = this.activeStreams.get(streamId);

    if (stream) {
      // Clear heartbeat interval
      if (stream.heartbeatInterval) {
        clearInterval(stream.heartbeatInterval);
      }

      // End response
      try {
        stream.response.end();
      } catch (error) {
        // Already ended
      }

      // Remove from active streams
      this.activeStreams.delete(streamId);
    }
  }

  /**
   * Delay helper
   */
  private delay(ms: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
}

// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
// EXPORT SINGLETON INSTANCE
// â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

export const streamingService = StreamingService.getInstance();